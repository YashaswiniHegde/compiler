#write an interpreter to run the assembly generated. To verify the ISA generated by assignment1.py
#implement the ISA instructions one by one for a single core and single matmul unit to begin with
#With global and local memories
#It can be in python
#Generation algorithm and interpreter or simulator should not have any code in common
import re
import numpy as np
class MatmulSimulator:
    def __init__(self, matmul_code):
        self.lines = [line.strip() for line in matmul_code.splitlines() if line.strip()]
        self.global_mem = np.arange(1073741824, dtype=np.float32) #1GB in bytes
        self.local_mem = np.arange(524288, dtype=np.float32)  #512KB in bytes

        #I would require this when more than one such cmd appear in ISA
        self.copylocal_cmd = {}
        self.copyglobal_cmd = {}
        self.matmul_cmd = {}
        
        self.Amatrix = np.zeros((32, 32), dtype=np.float32)
        self.Bmatrix = np.zeros((32, 32), dtype=np.float32)
        self.Cmatrix = np.zeros((32, 32), dtype=np.float32)

        self.A_row = 0
        self.A_col = 0
        self.B_row = 0
        self.B_col = 0
        self.C_row = 0
        self.C_col = 0
        self.C_offset = 0
        self.A_offset = 0
        self.B_offset = 0

        self.pc = 0  # program counter

    def load_ip_matrix_to_global(self,A_offset, A_matrix, B_offset, B_matrix, slice_size):
        self.global_mem[A_offset:A_offset + slice_size * slice_size] = A_matrix.flatten()
        self.global_mem[B_offset:B_offset + slice_size * slice_size] = B_matrix.flatten()
        return 

    def execute_line(self, line):

        if "cp_global_to_local" in line:
            #cp_global_to_local <C, [0:32:1, 0:32:1]>, core=0, <507904 /local_mem/, [0:32:1], [0:32:1]>
            cm = re.match(r"cp_global_to_local <C, \[(\d+):(\d+):(\d), (\d+):(\d+):(\d)\]>, core=(\d+), <(\d+) /local_mem/, \[(\d+):(\d+):(\d)\], \[(\d+):(\d+):(\d)\]>", line)
            if cm:
                crow_lower, crow_upper, crow_stride, ccol_lower, ccol_upper, crow_stride, corenum, coffset, coffset_row_lower, coffset_row_upper, coffset_row_stride, coffset_col_lower, coffset_col_upper, coffset_col_stride = cm.groups()
            return None     
            
            am = re.match(r"cp_global_to_local <A, \[(\d+):(\d+):(\d), (\d+):(\d+):(\d)\]>, core=(\d+), <(\d+) /local_mem/, \[(\d+):(\d+):(\d)\], \[(\d+):(\d+):(\d)\]>", line)
            if am:
                arow_lower, arow_upper, arow_stride, acol_lower, acol_upper, arow_stride, corenum, aoffset, aoffset_row_lower, aoffset_row_upper, aoffset_row_stride, aoffset_col_lower, aoffset_col_upper, aoffset_col_stride = m.groups()

                itemsize = self.global_mem.itemsize

                matrix_view = as_strided(
                self.global_mem[aoffset:], 
                shape=(arow_upper - arow_lower, acol_upper - acol_lower), 
                strides=(aoffset * itemsize, itemsize)
                )
                self.Amatrix=matrix_view[arow_lower:arow_upper, acol_lower:acol_upper]

            return None
            
            bm = re.match(r"cp_global_to_local <B, \[(\d+):(\d+):(\d), (\d+):(\d+):(\d)\]>, core=(\d+), <(\d+) /local_mem/, \[(\d+):(\d+):(\d)\], \[(\d+):(\d+):(\d)\]>", line)
            if bm:
                brow_lower, brow_upper, brow_stride, bcol_lower, bcol_upper, brow_stride, corenum, boffset, boffset_row_lower, boffset_row_upper, boffset_row_stride, boffset_col_lower, boffset_col_upper, boffset_col_stride = m.groups()
                itemsize = self.global_mem.itemsize

                matrix_view = as_strided(
                self.global_mem[boffset:], 
                shape=(brow_upper - brow_lower, bcol_upper - bcol_lower), 
                strides=(boffset * itemsize, itemsize)
                )
                self.Bmatrix=matrix_view[brow_lower:brow_upper, bcol_lower:bcol_upper]
            return None

        if "matmul" in line:
            #matmul core=0, matmul_unit=0, <0 /local_mem/, [0:32:1], [0:32:1]>, <4096 /local_mem/, [0:32:1], [0:32:1]>, <507904 /local_mem/, [0:32:1], [0:32:1]>, accumulator=True
            m = re.match(r"matmul core=(\d+), matmul_unit=(\d+), <(\d+) /local_mem/, \[(\d+):(\d+):(\d)\], \[(\d+):(\d+):(\d)\]>, <(\d+) /local_mem/, \[(\d+):(\d+):(\d)\], \[(\d+):(\d+):(\d)\]>, <(\d+) /local_mem/, \[(\d+):(\d+):(\d)\], \[(\d+):(\d+):(\d)\]>, accumulator=(\w+)", line)
            if m:
                arows,acols = self.Amatrix.shape
                brows,bcols = self.Bmatrix.shape
                for i in range(arows):
                    for j in range(bcols):
                        for k in range(acols):
                            self.Cmatrix[i][j] += self.Amatrix[i][k] * self.Bmatrix[k][j]
                return self.Cmatrix
        return None

        if "copy_local_to_global" in line:
            #cp_local_to_global <507904 /local_mem/, [0:32:1], [0:32:1]>,  <C, [0:32:1, 0:32:1]>
            cm = re.match(r"cp_local_to_global <(\d+) /local_mem/, \[(\d+):(\d+):(\d)\], \[(\d+):(\d+):(\d)\]>, <C, \[(\d+):(\d+):(\d), (\d+):(\d+):(\d)\]>", line)
            if cm:
                coffset, coffset_row_lower, coffset_row_upper, coffset_row_stride, coffset_col_lower, coffset_col_upper, coffset_col_stride, crow_lower, crow_upper, crow_stride, ccol_lower, ccol_upper, crow_stride = m.groups()
                self.global_mem[coffset:coffset + 32 * 32] = self.Cmatrix.flatten()

            return None

        return None

    def simulate(self):
        ret_val = None
        while self.pc < len(self.lines):
            line = self.lines[self.pc]
            result = self.execute_line(line)
            if result is not None:
                ret_val = result
                break
            self.pc += 1
        return ret_val


# --- Try it out ---
matmul_code = """
{
cp_global_to_local <C, [0:32:1, 0:32:1]>, core=0, <507904 /local_mem/, [0:32:1], [0:32:1]>
cp_global_to_local <A, [0:32:1, 0:32:1]>, core=0, <0 /local_mem/, [0:32:1], [0:32:1]>
cp_global_to_local <B, [0:32:1, 0:32:1]>, core=0, <4096 /local_mem/, [0:32:1], [0:32:1]>
matmul core=0, matmul_unit=0, <0 /local_mem/, [0:32:1], [0:32:1]>, <4096 /local_mem/, [0:32:1], [0:32:1]>, <507904 /local_mem/, [0:32:1], [0:32:1]>, accumulator=True
cp_local_to_global <507904 /local_mem/, [0:32:1], [0:32:1]>,  <C, [0:32:1, 0:32:1]>
}
"""

slice_size = 32
numRow = 32
numCol = 32

A_offset = 0
B_offset = 4096 #(32 * 32 * 4)

A_matrix = np.random.uniform(1.0, 100.0, size=(numRow, numCol)).astype(np.float32)
B_matrix = np.random.uniform(1.0, 100.0, size=(numRow, numCol)).astype(np.float32)

sim = MatmulSimulator(matmul_code)
sim.load_ip_matrix_to_global(A_offset, A_matrix, B_offset, B_matrix, slice_size)
result = sim.simulate()
#print("Returned Matrix:", result)